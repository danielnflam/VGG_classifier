{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7939c6bd-0a8d-4375-95db-3981e73d19fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Total Num Folds: 10\n",
      "Total Num Epochs: 23\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.datasets\n",
    "import torchvision.models\n",
    "import torchvision.transforms\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, SubsetRandomSampler, ConcatDataset\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from PIL import Image, ImageOps\n",
    "import os, sys, math, random, copy, time\n",
    "import datasets, custom_transforms, models\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "seed = 0\n",
    "split_k_folds=10\n",
    "flag_onlyFirstFold = False\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# Parameters to Change\n",
    "N_CLASSES = 2\n",
    "BATCH_SIZE = 4\n",
    "num_epochs_classifier=3\n",
    "num_epochs_finetune=20\n",
    "top_cutoff_percent = 0.15 # 0.08 COVID-Net paper by Wang et al.\n",
    "flag_includePneumoniaPics = False\n",
    "\n",
    "TRAINVAL_DATA_DIR = 'G:/DanielLam/DanielCustomNetwork/DanielDataSets_Reduced_256_Rajaraman_10KFold217/trainVal/'\n",
    "save_folder_name =  os.path.join(\"15cutoff_fineTune\", \"VGG16_Rajaraman_Rajaraman_10KFold217_NORMALCOVIDonly\")\n",
    "\n",
    "print(\"Total Num Folds: {}\".format(split_k_folds))\n",
    "print(\"Total Num Epochs: {}\".format(num_epochs_classifier + num_epochs_finetune))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0779c6-83f1-420a-aec5-6ce4d4050920",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c72d626-cde7-45e2-87fe-11391a51394f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOCKED\n",
    "# Preprocessing settings:\n",
    "interp_mode = torchvision.transforms.InterpolationMode.NEAREST\n",
    "image_size_to_VGG =224 # resize input images to this size in VGG\n",
    "model_name = \"VGG\"\n",
    "num_channels = 3 # because VGG is trained on RGB images\n",
    "unbias=True\n",
    "limit_save_epoch_acc=0.80\n",
    "\n",
    "\n",
    "# Learning Rates\n",
    "betas = (0.9,0.999)\n",
    "ini_lr= 1e-3\n",
    "max_layers_to_freeze = 28 # 30 means that only the last linear classifier is left to train\n",
    "class_weights = torch.Tensor([1, 1100/996]) # NONCOVID, COVID\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f1cfb2-cc4d-4dc2-b485-2e617e9934ee",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "907a6aea-da68-46b1-9b6a-85eef2747b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing and Transforms\n",
    "# Assumes importing images as PIL Images\n",
    "normalize = torchvision.transforms.Normalize(\n",
    "                                [0.485, 0.456, 0.406],\n",
    "                                [0.229, 0.224, 0.225])\n",
    "\n",
    "class Equalise(object):\n",
    "    # Histogram equalisation\n",
    "    # Only works on PIL images\n",
    "    def __init__(self, mask=None):\n",
    "        self.mask = mask\n",
    "    def __call__(self, image):\n",
    "        return ImageOps.equalize(image, self.mask)\n",
    "    \n",
    "class ImageComplement(object):\n",
    "    # Flip image intensities (i.e. black becomes white, white becomes black)\n",
    "    # Assumes input image is a tensor with range[0,1]\n",
    "    def __init__(self, probability=0.5):\n",
    "        self.probability = probability\n",
    "    def __call__(self, image):\n",
    "        activate = np.random.uniform(0,1)\n",
    "        if activate < self.probability:\n",
    "            # Flip\n",
    "            max_image = torch.max(image)\n",
    "            min_image = torch.min(image)\n",
    "            #print(\"min:{},max:{}\".format(min_image, max_image))\n",
    "            image = (image-min_image)/(max_image-min_image) # range [0,1]\n",
    "            image = (1-image)*(max_image-min_image) + min_image # back to original range\n",
    "        return image\n",
    "\n",
    "\n",
    "\n",
    "train_transforms=torchvision.transforms.Compose([\n",
    "                                    torchvision.transforms.ToTensor(),\n",
    "                                    custom_transforms.COVIDNetProcessing(top_cutoff_percent),\n",
    "                                    torchvision.transforms.Resize(image_size_to_VGG, interpolation=interp_mode), # PIL image\n",
    "                                    torchvision.transforms.CenterCrop(image_size_to_VGG),\n",
    "                                    torchvision.transforms.RandomHorizontalFlip(), \n",
    "                                    torchvision.transforms.ColorJitter(brightness=0.1), # this jitters brightness\n",
    "                                    torchvision.transforms.RandomAffine(degrees=10,translate=(0.1,0.1),scale=(0.9,1.1)),\n",
    "                                    ImageComplement(),\n",
    "                                    normalize,\n",
    "                                    ])\n",
    "\n",
    "val_transforms=torchvision.transforms.Compose([\n",
    "                                    torchvision.transforms.ToTensor(),\n",
    "                                    custom_transforms.COVIDNetProcessing(top_cutoff_percent),\n",
    "                                    torchvision.transforms.Resize(image_size_to_VGG, interpolation=interp_mode),\n",
    "                                    torchvision.transforms.CenterCrop(image_size_to_VGG),\n",
    "                                    normalize,\n",
    "                                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb6a3ee-04ce-4476-8392-5df8ef981f1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "03e10bdf-793e-4cf0-a5f3-af0aac5a9555",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0964cfc4-530b-46b3-bc01-35fa4cba5014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None Path\n",
      "RAW DATASET STATISTICS:-----------\n",
      "Normal:1100, Pneumonia:0, COVID:996\n",
      "2-Class Dataset Statistics:-----------\n",
      "Noncovid:1100, COVID:996\n",
      "===========\n",
      "Fold 1\n",
      "===========\n",
      "===========\n",
      "dict_keys(['name', 'image', 'label'])\n",
      "dict_keys(['name', 'image', 'label'])\n",
      "Parameters total:  14715714\n",
      "Parameters trainable:  1026\n",
      "Epoch 1/3\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.4912 Acc: 0.8012\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.2886 Acc: 0.9190\n",
      "Epoch 2/3\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.3341 Acc: 0.8913\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.2117 Acc: 0.9190\n",
      "Epoch 3/3\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2974 Acc: 0.8887\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1840 Acc: 0.9333\n",
      "Training complete in 1m 30s\n",
      "Best val Acc: 0.000000\n",
      "+++++++\n",
      "Fine-Tuning\n",
      "+++++++\n",
      "Parameters total:  14715714\n",
      "Parameters trainable:  7080450\n",
      "Epoch 4/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2829 Acc: 0.9008\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1824 Acc: 0.9333\n",
      "Epoch 5/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2781 Acc: 0.9072\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1807 Acc: 0.9333\n",
      "Epoch 6/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2750 Acc: 0.9035\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1787 Acc: 0.9333\n",
      "Epoch 7/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2940 Acc: 0.8897\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1776 Acc: 0.9333\n",
      "Epoch 8/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2792 Acc: 0.9003\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1768 Acc: 0.9333\n",
      "Epoch 9/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2728 Acc: 0.8998\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1753 Acc: 0.9333\n",
      "Epoch 10/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2698 Acc: 0.9067\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1745 Acc: 0.9333\n",
      "Epoch 11/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2747 Acc: 0.9072\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1729 Acc: 0.9333\n",
      "Epoch 12/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2733 Acc: 0.9014\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1723 Acc: 0.9333\n",
      "Epoch 13/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2740 Acc: 0.8982\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1698 Acc: 0.9333\n",
      "Epoch 14/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2658 Acc: 0.9046\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1686 Acc: 0.9333\n",
      "Epoch 15/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2577 Acc: 0.9109\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1681 Acc: 0.9333\n",
      "Epoch 16/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2751 Acc: 0.9051\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1657 Acc: 0.9333\n",
      "Epoch 17/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2703 Acc: 0.8961\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1657 Acc: 0.9333\n",
      "Epoch 18/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2601 Acc: 0.9067\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1647 Acc: 0.9333\n",
      "Epoch 19/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2500 Acc: 0.9162\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1633 Acc: 0.9333\n",
      "Epoch 20/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2524 Acc: 0.9046\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1627 Acc: 0.9333\n",
      "Epoch 21/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2529 Acc: 0.9109\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1606 Acc: 0.9333\n",
      "Epoch 22/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2502 Acc: 0.9109\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1607 Acc: 0.9333\n",
      "Epoch 23/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2517 Acc: 0.9146\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1589 Acc: 0.9333\n",
      "Training complete in 9m 52s\n",
      "Best val Acc: 0.000000\n",
      "Saved checkpoint: checkpoints\\2Class\\15cutoff_fineTune\\VGG16_Rajaraman_Rajaraman_10KFold217_NORMALCOVIDonly\\Fold1[classifier3_finetune20].pt\n",
      "Fold 2\n",
      "===========\n",
      "===========\n",
      "dict_keys(['name', 'image', 'label'])\n",
      "dict_keys(['name', 'image', 'label'])\n",
      "Parameters total:  14715714\n",
      "Parameters trainable:  1026\n",
      "Epoch 1/3\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.4942 Acc: 0.7975\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.3479 Acc: 0.8857\n",
      "Epoch 2/3\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.3456 Acc: 0.8717\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.2161 Acc: 0.9524\n",
      "Epoch 3/3\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2997 Acc: 0.8876\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1956 Acc: 0.9333\n",
      "Training complete in 1m 25s\n",
      "Best val Acc: 0.000000\n",
      "+++++++\n",
      "Fine-Tuning\n",
      "+++++++\n",
      "Parameters total:  14715714\n",
      "Parameters trainable:  7080450\n",
      "Epoch 4/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2984 Acc: 0.8876\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1913 Acc: 0.9333\n",
      "Epoch 5/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2872 Acc: 0.8818\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1875 Acc: 0.9381\n",
      "Epoch 6/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2951 Acc: 0.8796\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1856 Acc: 0.9381\n",
      "Epoch 7/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2889 Acc: 0.9008\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1831 Acc: 0.9381\n",
      "Epoch 8/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2964 Acc: 0.8802\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1810 Acc: 0.9381\n",
      "Epoch 9/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2734 Acc: 0.8987\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1802 Acc: 0.9381\n",
      "Epoch 10/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2751 Acc: 0.9046\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1786 Acc: 0.9429\n",
      "Epoch 11/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2783 Acc: 0.8966\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1768 Acc: 0.9429\n",
      "Epoch 12/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2769 Acc: 0.8971\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1759 Acc: 0.9429\n",
      "Epoch 13/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2705 Acc: 0.8966\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1733 Acc: 0.9429\n",
      "Epoch 14/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2668 Acc: 0.9040\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1726 Acc: 0.9429\n",
      "Epoch 15/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2746 Acc: 0.8955\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1707 Acc: 0.9429\n",
      "Epoch 16/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2795 Acc: 0.8993\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1703 Acc: 0.9429\n",
      "Epoch 17/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2610 Acc: 0.9040\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1684 Acc: 0.9429\n",
      "Epoch 18/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2683 Acc: 0.9072\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1678 Acc: 0.9429\n",
      "Epoch 19/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2733 Acc: 0.8998\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1659 Acc: 0.9476\n",
      "Epoch 20/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2825 Acc: 0.8966\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1656 Acc: 0.9476\n",
      "Epoch 21/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2617 Acc: 0.9067\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1637 Acc: 0.9476\n",
      "Epoch 22/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2522 Acc: 0.9083\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1637 Acc: 0.9429\n",
      "Epoch 23/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2579 Acc: 0.9136\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1621 Acc: 0.9429\n",
      "Training complete in 9m 53s\n",
      "Best val Acc: 0.000000\n",
      "Saved checkpoint: checkpoints\\2Class\\15cutoff_fineTune\\VGG16_Rajaraman_Rajaraman_10KFold217_NORMALCOVIDonly\\Fold2[classifier3_finetune20].pt\n",
      "Fold 3\n",
      "===========\n",
      "===========\n",
      "dict_keys(['name', 'image', 'label'])\n",
      "dict_keys(['name', 'image', 'label'])\n",
      "Parameters total:  14715714\n",
      "Parameters trainable:  1026\n",
      "Epoch 1/3\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.4672 Acc: 0.8224\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.2583 Acc: 0.9524\n",
      "Epoch 2/3\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.3344 Acc: 0.8876\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.2132 Acc: 0.9429\n",
      "Epoch 3/3\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2974 Acc: 0.8924\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1479 Acc: 0.9714\n",
      "Training complete in 1m 25s\n",
      "Best val Acc: 0.000000\n",
      "+++++++\n",
      "Fine-Tuning\n",
      "+++++++\n",
      "Parameters total:  14715714\n",
      "Parameters trainable:  7080450\n",
      "Epoch 4/23\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train dataset: 1886\n",
      "train Loss: 0.2826 Acc: 0.9008\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1470 Acc: 0.9714\n",
      "Epoch 5/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2751 Acc: 0.8993\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1452 Acc: 0.9714\n",
      "Epoch 6/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2690 Acc: 0.8977\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1437 Acc: 0.9714\n",
      "Epoch 7/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2798 Acc: 0.8977\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1427 Acc: 0.9714\n",
      "Epoch 8/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2819 Acc: 0.9003\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1410 Acc: 0.9714\n",
      "Epoch 9/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2796 Acc: 0.8950\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1390 Acc: 0.9714\n",
      "Epoch 10/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2672 Acc: 0.9067\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1385 Acc: 0.9762\n",
      "Epoch 11/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2688 Acc: 0.8971\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1372 Acc: 0.9762\n",
      "Epoch 12/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2657 Acc: 0.9019\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1361 Acc: 0.9762\n",
      "Epoch 13/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2697 Acc: 0.9035\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1348 Acc: 0.9714\n",
      "Epoch 14/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2670 Acc: 0.9067\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1333 Acc: 0.9714\n",
      "Epoch 15/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2646 Acc: 0.9035\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1318 Acc: 0.9714\n",
      "Epoch 16/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2662 Acc: 0.9030\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1305 Acc: 0.9714\n",
      "Epoch 17/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2549 Acc: 0.9109\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1287 Acc: 0.9714\n",
      "Epoch 18/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2616 Acc: 0.9077\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1285 Acc: 0.9714\n",
      "Epoch 19/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2513 Acc: 0.9040\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1269 Acc: 0.9714\n",
      "Epoch 20/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2486 Acc: 0.9120\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1252 Acc: 0.9714\n",
      "Epoch 21/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2586 Acc: 0.9088\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1247 Acc: 0.9714\n",
      "Epoch 22/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2610 Acc: 0.9077\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1234 Acc: 0.9714\n",
      "Epoch 23/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2612 Acc: 0.9008\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1222 Acc: 0.9714\n",
      "Training complete in 9m 51s\n",
      "Best val Acc: 0.000000\n",
      "Saved checkpoint: checkpoints\\2Class\\15cutoff_fineTune\\VGG16_Rajaraman_Rajaraman_10KFold217_NORMALCOVIDonly\\Fold3[classifier3_finetune20].pt\n",
      "Fold 4\n",
      "===========\n",
      "===========\n",
      "dict_keys(['name', 'image', 'label'])\n",
      "dict_keys(['name', 'image', 'label'])\n",
      "Parameters total:  14715714\n",
      "Parameters trainable:  1026\n",
      "Epoch 1/3\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.4782 Acc: 0.8144\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.2983 Acc: 0.9381\n",
      "Epoch 2/3\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.3353 Acc: 0.8865\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.2518 Acc: 0.9190\n",
      "Epoch 3/3\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2934 Acc: 0.8902\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.2121 Acc: 0.9333\n",
      "Training complete in 1m 25s\n",
      "Best val Acc: 0.000000\n",
      "+++++++\n",
      "Fine-Tuning\n",
      "+++++++\n",
      "Parameters total:  14715714\n",
      "Parameters trainable:  7080450\n",
      "Epoch 4/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2887 Acc: 0.8908\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.2061 Acc: 0.9333\n",
      "Epoch 5/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2855 Acc: 0.8940\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.2033 Acc: 0.9333\n",
      "Epoch 6/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2888 Acc: 0.8918\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.2004 Acc: 0.9381\n",
      "Epoch 7/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2742 Acc: 0.8961\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1992 Acc: 0.9429\n",
      "Epoch 8/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.3006 Acc: 0.8844\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1966 Acc: 0.9429\n",
      "Epoch 9/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2751 Acc: 0.9019\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1954 Acc: 0.9429\n",
      "Epoch 10/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2605 Acc: 0.9146\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1934 Acc: 0.9429\n",
      "Epoch 11/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2691 Acc: 0.9040\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1933 Acc: 0.9429\n",
      "Epoch 12/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2762 Acc: 0.8966\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1904 Acc: 0.9429\n",
      "Epoch 13/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2878 Acc: 0.8908\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1894 Acc: 0.9429\n",
      "Epoch 14/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2604 Acc: 0.9035\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1886 Acc: 0.9429\n",
      "Epoch 15/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2762 Acc: 0.8993\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1858 Acc: 0.9429\n",
      "Epoch 16/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2747 Acc: 0.9014\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1855 Acc: 0.9476\n",
      "Epoch 17/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2731 Acc: 0.9051\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1829 Acc: 0.9476\n",
      "Epoch 18/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2693 Acc: 0.8982\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1832 Acc: 0.9476\n",
      "Epoch 19/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2716 Acc: 0.9030\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1809 Acc: 0.9476\n",
      "Epoch 20/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2690 Acc: 0.9003\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1808 Acc: 0.9524\n",
      "Epoch 21/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2612 Acc: 0.9051\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1789 Acc: 0.9524\n",
      "Epoch 22/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2708 Acc: 0.9024\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1784 Acc: 0.9524\n",
      "Epoch 23/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2644 Acc: 0.9040\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1774 Acc: 0.9524\n",
      "Training complete in 9m 50s\n",
      "Best val Acc: 0.000000\n",
      "Saved checkpoint: checkpoints\\2Class\\15cutoff_fineTune\\VGG16_Rajaraman_Rajaraman_10KFold217_NORMALCOVIDonly\\Fold4[classifier3_finetune20].pt\n",
      "Fold 5\n",
      "===========\n",
      "===========\n",
      "dict_keys(['name', 'image', 'label'])\n",
      "dict_keys(['name', 'image', 'label'])\n",
      "Parameters total:  14715714\n",
      "Parameters trainable:  1026\n",
      "Epoch 1/3\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.4736 Acc: 0.8208\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.3131 Acc: 0.9286\n",
      "Epoch 2/3\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.3259 Acc: 0.8887\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.2477 Acc: 0.9333\n",
      "Epoch 3/3\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.3024 Acc: 0.8876\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.2454 Acc: 0.9238\n",
      "Training complete in 1m 25s\n",
      "Best val Acc: 0.000000\n",
      "+++++++\n",
      "Fine-Tuning\n",
      "+++++++\n",
      "Parameters total:  14715714\n",
      "Parameters trainable:  7080450\n",
      "Epoch 4/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2874 Acc: 0.8918\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.2366 Acc: 0.9238\n",
      "Epoch 5/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2849 Acc: 0.8908\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.2312 Acc: 0.9286\n",
      "Epoch 6/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2841 Acc: 0.8929\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.2255 Acc: 0.9286\n",
      "Epoch 7/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2719 Acc: 0.8982\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.2240 Acc: 0.9286\n",
      "Epoch 8/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2719 Acc: 0.9014\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.2234 Acc: 0.9286\n",
      "Epoch 9/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2672 Acc: 0.9008\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.2193 Acc: 0.9286\n",
      "Epoch 10/23\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train dataset: 1886\n",
      "train Loss: 0.2648 Acc: 0.9067\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.2171 Acc: 0.9286\n",
      "Epoch 11/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2841 Acc: 0.8961\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.2159 Acc: 0.9286\n",
      "Epoch 12/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2727 Acc: 0.8955\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.2143 Acc: 0.9333\n",
      "Epoch 13/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2808 Acc: 0.8940\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.2132 Acc: 0.9333\n",
      "Epoch 14/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2578 Acc: 0.9083\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.2113 Acc: 0.9333\n",
      "Epoch 15/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2709 Acc: 0.9003\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.2107 Acc: 0.9333\n",
      "Epoch 16/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2735 Acc: 0.9030\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.2096 Acc: 0.9333\n",
      "Epoch 17/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2701 Acc: 0.9093\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.2065 Acc: 0.9333\n",
      "Epoch 18/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2632 Acc: 0.9067\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.2062 Acc: 0.9381\n",
      "Epoch 19/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2657 Acc: 0.9077\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.2054 Acc: 0.9381\n",
      "Epoch 20/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2622 Acc: 0.8998\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.2054 Acc: 0.9381\n",
      "Epoch 21/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2594 Acc: 0.9083\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.2018 Acc: 0.9381\n",
      "Epoch 22/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2521 Acc: 0.9072\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.2011 Acc: 0.9381\n",
      "Epoch 23/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2569 Acc: 0.9093\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1999 Acc: 0.9381\n",
      "Training complete in 9m 50s\n",
      "Best val Acc: 0.000000\n",
      "Saved checkpoint: checkpoints\\2Class\\15cutoff_fineTune\\VGG16_Rajaraman_Rajaraman_10KFold217_NORMALCOVIDonly\\Fold5[classifier3_finetune20].pt\n",
      "Fold 6\n",
      "===========\n",
      "===========\n",
      "dict_keys(['name', 'image', 'label'])\n",
      "dict_keys(['name', 'image', 'label'])\n",
      "Parameters total:  14715714\n",
      "Parameters trainable:  1026\n",
      "Epoch 1/3\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.4898 Acc: 0.7964\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.3085 Acc: 0.9190\n",
      "Epoch 2/3\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.3456 Acc: 0.8696\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.2408 Acc: 0.9333\n",
      "Epoch 3/3\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2962 Acc: 0.8892\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.2084 Acc: 0.9286\n",
      "Training complete in 1m 26s\n",
      "Best val Acc: 0.000000\n",
      "+++++++\n",
      "Fine-Tuning\n",
      "+++++++\n",
      "Parameters total:  14715714\n",
      "Parameters trainable:  7080450\n",
      "Epoch 4/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2903 Acc: 0.8892\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.2074 Acc: 0.9333\n",
      "Epoch 5/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2789 Acc: 0.9024\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.2049 Acc: 0.9333\n",
      "Epoch 6/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2855 Acc: 0.8929\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.2045 Acc: 0.9333\n",
      "Epoch 7/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2763 Acc: 0.8993\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.2030 Acc: 0.9333\n",
      "Epoch 8/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2854 Acc: 0.8945\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.2013 Acc: 0.9381\n",
      "Epoch 9/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2681 Acc: 0.8945\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1993 Acc: 0.9381\n",
      "Epoch 10/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2742 Acc: 0.8945\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1994 Acc: 0.9381\n",
      "Epoch 11/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2661 Acc: 0.9056\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1974 Acc: 0.9381\n",
      "Epoch 12/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2620 Acc: 0.9067\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1954 Acc: 0.9381\n",
      "Epoch 13/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2679 Acc: 0.8998\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1947 Acc: 0.9381\n",
      "Epoch 14/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2623 Acc: 0.9030\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1942 Acc: 0.9381\n",
      "Epoch 15/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2790 Acc: 0.8977\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1926 Acc: 0.9381\n",
      "Epoch 16/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2673 Acc: 0.9056\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1920 Acc: 0.9381\n",
      "Epoch 17/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2613 Acc: 0.8993\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1900 Acc: 0.9381\n",
      "Epoch 18/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2538 Acc: 0.9083\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1895 Acc: 0.9429\n",
      "Epoch 19/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2764 Acc: 0.8971\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1872 Acc: 0.9429\n",
      "Epoch 20/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2662 Acc: 0.9051\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1870 Acc: 0.9429\n",
      "Epoch 21/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2470 Acc: 0.9146\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1858 Acc: 0.9476\n",
      "Epoch 22/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2465 Acc: 0.9099\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1848 Acc: 0.9476\n",
      "Epoch 23/23\n",
      "----------\n",
      "Length of train dataset: 1886\n",
      "train Loss: 0.2424 Acc: 0.9136\n",
      "Length of val dataset: 210\n",
      "val Loss: 0.1838 Acc: 0.9476\n",
      "Training complete in 9m 50s\n",
      "Best val Acc: 0.000000\n",
      "Saved checkpoint: checkpoints\\2Class\\15cutoff_fineTune\\VGG16_Rajaraman_Rajaraman_10KFold217_NORMALCOVIDonly\\Fold6[classifier3_finetune20].pt\n",
      "Fold 7\n",
      "===========\n",
      "===========\n",
      "dict_keys(['name', 'image', 'label'])\n",
      "dict_keys(['name', 'image', 'label'])\n",
      "Parameters total:  14715714\n",
      "Parameters trainable:  1026\n",
      "Epoch 1/3\n",
      "----------\n",
      "Length of train dataset: 1887\n",
      "train Loss: 0.4739 Acc: 0.8034\n",
      "Length of val dataset: 209\n",
      "val Loss: 0.2790 Acc: 0.9522\n",
      "Epoch 2/3\n",
      "----------\n",
      "Length of train dataset: 1887\n",
      "train Loss: 0.3444 Acc: 0.8786\n",
      "Length of val dataset: 209\n",
      "val Loss: 0.2171 Acc: 0.9426\n",
      "Epoch 3/3\n",
      "----------\n",
      "Length of train dataset: 1887\n",
      "train Loss: 0.3088 Acc: 0.8935\n",
      "Length of val dataset: 209\n",
      "val Loss: 0.1664 Acc: 0.9761\n",
      "Training complete in 1m 25s\n",
      "Best val Acc: 0.000000\n",
      "+++++++\n",
      "Fine-Tuning\n",
      "+++++++\n",
      "Parameters total:  14715714\n",
      "Parameters trainable:  7080450\n",
      "Epoch 4/23\n",
      "----------\n",
      "Length of train dataset: 1887\n",
      "train Loss: 0.2852 Acc: 0.8871\n",
      "Length of val dataset: 209\n",
      "val Loss: 0.1653 Acc: 0.9761\n",
      "Epoch 5/23\n",
      "----------\n",
      "Length of train dataset: 1887\n",
      "train Loss: 0.2763 Acc: 0.9046\n",
      "Length of val dataset: 209\n",
      "val Loss: 0.1642 Acc: 0.9713\n",
      "Epoch 6/23\n",
      "----------\n",
      "Length of train dataset: 1887\n",
      "train Loss: 0.2604 Acc: 0.9046\n",
      "Length of val dataset: 209\n",
      "val Loss: 0.1640 Acc: 0.9713\n",
      "Epoch 7/23\n",
      "----------\n",
      "Length of train dataset: 1887\n",
      "train Loss: 0.2713 Acc: 0.8935\n",
      "Length of val dataset: 209\n",
      "val Loss: 0.1630 Acc: 0.9713\n",
      "Epoch 8/23\n",
      "----------\n",
      "Length of train dataset: 1887\n",
      "train Loss: 0.2792 Acc: 0.8914\n",
      "Length of val dataset: 209\n",
      "val Loss: 0.1628 Acc: 0.9713\n",
      "Epoch 9/23\n",
      "----------\n",
      "Length of train dataset: 1887\n",
      "train Loss: 0.2825 Acc: 0.8935\n",
      "Length of val dataset: 209\n",
      "val Loss: 0.1610 Acc: 0.9713\n",
      "Epoch 10/23\n",
      "----------\n",
      "Length of train dataset: 1887\n",
      "train Loss: 0.2675 Acc: 0.8972\n",
      "Length of val dataset: 209\n",
      "val Loss: 0.1593 Acc: 0.9713\n",
      "Epoch 11/23\n",
      "----------\n",
      "Length of train dataset: 1887\n",
      "train Loss: 0.2654 Acc: 0.9094\n",
      "Length of val dataset: 209\n",
      "val Loss: 0.1603 Acc: 0.9713\n",
      "Epoch 12/23\n",
      "----------\n",
      "Length of train dataset: 1887\n",
      "train Loss: 0.2615 Acc: 0.9051\n",
      "Length of val dataset: 209\n",
      "val Loss: 0.1589 Acc: 0.9713\n",
      "Epoch 13/23\n",
      "----------\n",
      "Length of train dataset: 1887\n",
      "train Loss: 0.2575 Acc: 0.9051\n",
      "Length of val dataset: 209\n",
      "val Loss: 0.1582 Acc: 0.9713\n",
      "Epoch 14/23\n",
      "----------\n",
      "Length of train dataset: 1887\n",
      "train Loss: 0.2615 Acc: 0.9089\n",
      "Length of val dataset: 209\n",
      "val Loss: 0.1567 Acc: 0.9713\n",
      "Epoch 15/23\n",
      "----------\n",
      "Length of train dataset: 1887\n",
      "train Loss: 0.2680 Acc: 0.9020\n",
      "Length of val dataset: 209\n",
      "val Loss: 0.1560 Acc: 0.9713\n",
      "Epoch 16/23\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train dataset: 1887\n",
      "train Loss: 0.2697 Acc: 0.8972\n",
      "Length of val dataset: 209\n",
      "val Loss: 0.1540 Acc: 0.9713\n",
      "Epoch 17/23\n",
      "----------\n",
      "Length of train dataset: 1887\n",
      "train Loss: 0.2548 Acc: 0.9094\n",
      "Length of val dataset: 209\n",
      "val Loss: 0.1532 Acc: 0.9713\n",
      "Epoch 18/23\n",
      "----------\n",
      "Length of train dataset: 1887\n",
      "train Loss: 0.2704 Acc: 0.9009\n",
      "Length of val dataset: 209\n",
      "val Loss: 0.1517 Acc: 0.9713\n",
      "Epoch 19/23\n",
      "----------\n",
      "Length of train dataset: 1887\n",
      "train Loss: 0.2639 Acc: 0.8945\n",
      "Length of val dataset: 209\n",
      "val Loss: 0.1527 Acc: 0.9713\n",
      "Epoch 20/23\n",
      "----------\n",
      "Length of train dataset: 1887\n",
      "train Loss: 0.2499 Acc: 0.9099\n",
      "Length of val dataset: 209\n",
      "val Loss: 0.1507 Acc: 0.9713\n",
      "Epoch 21/23\n",
      "----------\n",
      "Length of train dataset: 1887\n",
      "train Loss: 0.2612 Acc: 0.9009\n",
      "Length of val dataset: 209\n",
      "val Loss: 0.1503 Acc: 0.9713\n",
      "Epoch 22/23\n",
      "----------\n",
      "Length of train dataset: 1887\n",
      "train Loss: 0.2625 Acc: 0.9041\n",
      "Length of val dataset: 209\n",
      "val Loss: 0.1491 Acc: 0.9713\n",
      "Epoch 23/23\n",
      "----------\n",
      "Length of train dataset: 1887\n",
      "train Loss: 0.2550 Acc: 0.9036\n",
      "Length of val dataset: 209\n",
      "val Loss: 0.1484 Acc: 0.9713\n",
      "Training complete in 9m 50s\n",
      "Best val Acc: 0.000000\n",
      "Saved checkpoint: checkpoints\\2Class\\15cutoff_fineTune\\VGG16_Rajaraman_Rajaraman_10KFold217_NORMALCOVIDonly\\Fold7[classifier3_finetune20].pt\n",
      "Fold 8\n",
      "===========\n",
      "===========\n",
      "dict_keys(['name', 'image', 'label'])\n",
      "dict_keys(['name', 'image', 'label'])\n",
      "Parameters total:  14715714\n",
      "Parameters trainable:  1026\n",
      "Epoch 1/3\n",
      "----------\n",
      "Length of train dataset: 1887\n",
      "train Loss: 0.4763 Acc: 0.8209\n",
      "Length of val dataset: 209\n",
      "val Loss: 0.2757 Acc: 0.9569\n",
      "Epoch 2/3\n",
      "----------\n",
      "Length of train dataset: 1887\n",
      "train Loss: 0.3346 Acc: 0.8792\n",
      "Length of val dataset: 209\n",
      "val Loss: 0.2035 Acc: 0.9474\n",
      "Epoch 3/3\n",
      "----------\n",
      "Length of train dataset: 1887\n",
      "train Loss: 0.2929 Acc: 0.8935\n",
      "Length of val dataset: 209\n",
      "val Loss: 0.1739 Acc: 0.9474\n",
      "Training complete in 1m 25s\n",
      "Best val Acc: 0.000000\n",
      "+++++++\n",
      "Fine-Tuning\n",
      "+++++++\n",
      "Parameters total:  14715714\n",
      "Parameters trainable:  7080450\n",
      "Epoch 4/23\n",
      "----------\n",
      "Length of train dataset: 1887\n",
      "train Loss: 0.2730 Acc: 0.9009\n",
      "Length of val dataset: 209\n",
      "val Loss: 0.1712 Acc: 0.9474\n",
      "Epoch 5/23\n",
      "----------\n",
      "Length of train dataset: 1887\n",
      "train Loss: 0.2823 Acc: 0.8940\n",
      "Length of val dataset: 209\n",
      "val Loss: 0.1712 Acc: 0.9474\n",
      "Epoch 6/23\n",
      "----------\n",
      "Length of train dataset: 1887\n",
      "train Loss: 0.2642 Acc: 0.9083\n",
      "Length of val dataset: 209\n",
      "val Loss: 0.1694 Acc: 0.9474\n",
      "Epoch 7/23\n",
      "----------\n",
      "Length of train dataset: 1887\n",
      "train Loss: 0.2823 Acc: 0.8919\n",
      "Length of val dataset: 209\n",
      "val Loss: 0.1683 Acc: 0.9474\n",
      "Epoch 8/23\n",
      "----------\n",
      "Length of train dataset: 1887\n",
      "train Loss: 0.2681 Acc: 0.9014\n",
      "Length of val dataset: 209\n",
      "val Loss: 0.1678 Acc: 0.9474\n",
      "Epoch 9/23\n",
      "----------\n",
      "Length of train dataset: 1887\n",
      "train Loss: 0.2735 Acc: 0.8993\n",
      "Length of val dataset: 209\n",
      "val Loss: 0.1666 Acc: 0.9474\n",
      "Epoch 10/23\n",
      "----------\n",
      "Length of train dataset: 1887\n",
      "train Loss: 0.2722 Acc: 0.8956\n",
      "Length of val dataset: 209\n",
      "val Loss: 0.1642 Acc: 0.9474\n",
      "Epoch 11/23\n",
      "----------\n",
      "Length of train dataset: 1887\n",
      "train Loss: 0.2762 Acc: 0.9014\n",
      "Length of val dataset: 209\n",
      "val Loss: 0.1631 Acc: 0.9474\n",
      "Epoch 12/23\n",
      "----------\n",
      "Length of train dataset: 1887\n",
      "train Loss: 0.2760 Acc: 0.8961\n",
      "Length of val dataset: 209\n",
      "val Loss: 0.1625 Acc: 0.9474\n",
      "Epoch 13/23\n",
      "----------\n",
      "Length of train dataset: 1887\n",
      "train Loss: 0.2738 Acc: 0.8945\n",
      "Length of val dataset: 209\n",
      "val Loss: 0.1608 Acc: 0.9474\n",
      "Epoch 14/23\n",
      "----------\n",
      "Length of train dataset: 1887\n",
      "train Loss: 0.2778 Acc: 0.8908\n",
      "Length of val dataset: 209\n",
      "val Loss: 0.1605 Acc: 0.9522\n",
      "Epoch 15/23\n",
      "----------\n",
      "Length of train dataset: 1887\n",
      "train Loss: 0.2514 Acc: 0.9073\n",
      "Length of val dataset: 209\n",
      "val Loss: 0.1587 Acc: 0.9522\n",
      "Epoch 16/23\n",
      "----------\n",
      "Length of train dataset: 1887\n",
      "train Loss: 0.2586 Acc: 0.9067\n",
      "Length of val dataset: 209\n",
      "val Loss: 0.1575 Acc: 0.9522\n",
      "Epoch 17/23\n",
      "----------\n",
      "Length of train dataset: 1887\n",
      "train Loss: 0.2612 Acc: 0.8983\n",
      "Length of val dataset: 209\n",
      "val Loss: 0.1560 Acc: 0.9522\n",
      "Epoch 18/23\n",
      "----------\n",
      "Length of train dataset: 1887\n",
      "train Loss: 0.2660 Acc: 0.9057\n",
      "Length of val dataset: 209\n",
      "val Loss: 0.1544 Acc: 0.9522\n",
      "Epoch 19/23\n",
      "----------\n",
      "Length of train dataset: 1887\n",
      "train Loss: 0.2583 Acc: 0.9073\n",
      "Length of val dataset: 209\n",
      "val Loss: 0.1538 Acc: 0.9522\n",
      "Epoch 20/23\n",
      "----------\n",
      "Length of train dataset: 1887\n",
      "train Loss: 0.2454 Acc: 0.9115\n",
      "Length of val dataset: 209\n",
      "val Loss: 0.1527 Acc: 0.9522\n",
      "Epoch 21/23\n",
      "----------\n",
      "Length of train dataset: 1887\n",
      "train Loss: 0.2539 Acc: 0.9115\n",
      "Length of val dataset: 209\n",
      "val Loss: 0.1519 Acc: 0.9522\n",
      "Epoch 22/23\n",
      "----------\n",
      "Length of train dataset: 1887\n",
      "train Loss: 0.2483 Acc: 0.9067\n",
      "Length of val dataset: 209\n",
      "val Loss: 0.1503 Acc: 0.9522\n",
      "Epoch 23/23\n",
      "----------\n",
      "Length of train dataset: 1887\n",
      "train Loss: 0.2728 Acc: 0.9004\n",
      "Length of val dataset: 209\n",
      "val Loss: 0.1497 Acc: 0.9522\n",
      "Training complete in 9m 50s\n",
      "Best val Acc: 0.000000\n",
      "Saved checkpoint: checkpoints\\2Class\\15cutoff_fineTune\\VGG16_Rajaraman_Rajaraman_10KFold217_NORMALCOVIDonly\\Fold8[classifier3_finetune20].pt\n",
      "Fold 9\n",
      "===========\n",
      "===========\n",
      "dict_keys(['name', 'image', 'label'])\n",
      "dict_keys(['name', 'image', 'label'])\n",
      "Parameters total:  14715714\n",
      "Parameters trainable:  1026\n",
      "Epoch 1/3\n",
      "----------\n",
      "Length of train dataset: 1887\n",
      "train Loss: 0.4806 Acc: 0.8108\n",
      "Length of val dataset: 209\n",
      "val Loss: 0.2933 Acc: 0.9234\n",
      "Epoch 2/3\n",
      "----------\n",
      "Length of train dataset: 1887\n",
      "train Loss: 0.3402 Acc: 0.8707\n",
      "Length of val dataset: 209\n",
      "val Loss: 0.2206 Acc: 0.9234\n",
      "Epoch 3/3\n",
      "----------\n",
      "Length of train dataset: 1887\n",
      "train Loss: 0.2974 Acc: 0.8898\n",
      "Length of val dataset: 209\n",
      "val Loss: 0.1904 Acc: 0.9330\n",
      "Training complete in 1m 25s\n",
      "Best val Acc: 0.000000\n",
      "+++++++\n",
      "Fine-Tuning\n",
      "+++++++\n",
      "Parameters total:  14715714\n",
      "Parameters trainable:  7080450\n",
      "Epoch 4/23\n",
      "----------\n",
      "Length of train dataset: 1887\n",
      "train Loss: 0.2864 Acc: 0.8792\n",
      "Length of val dataset: 209\n",
      "val Loss: 0.1912 Acc: 0.9330\n",
      "Epoch 5/23\n",
      "----------\n",
      "Length of train dataset: 1887\n",
      "train Loss: 0.2800 Acc: 0.8972\n",
      "Length of val dataset: 209\n",
      "val Loss: 0.1921 Acc: 0.9330\n",
      "Epoch 6/23\n",
      "----------\n",
      "Length of train dataset: 1887\n",
      "train Loss: 0.2834 Acc: 0.8919\n",
      "Length of val dataset: 209\n",
      "val Loss: 0.1897 Acc: 0.9330\n",
      "Epoch 7/23\n",
      "----------\n",
      "Length of train dataset: 1887\n",
      "train Loss: 0.2813 Acc: 0.8930\n",
      "Length of val dataset: 209\n",
      "val Loss: 0.1897 Acc: 0.9378\n",
      "Epoch 8/23\n",
      "----------\n",
      "Length of train dataset: 1887\n",
      "train Loss: 0.2862 Acc: 0.8861\n",
      "Length of val dataset: 209\n",
      "val Loss: 0.1883 Acc: 0.9378\n",
      "Epoch 9/23\n",
      "----------\n",
      "Length of train dataset: 1887\n",
      "train Loss: 0.2780 Acc: 0.8919\n",
      "Length of val dataset: 209\n",
      "val Loss: 0.1892 Acc: 0.9378\n",
      "Epoch 10/23\n",
      "----------\n",
      "Length of train dataset: 1887\n",
      "train Loss: 0.2699 Acc: 0.9030\n",
      "Length of val dataset: 209\n",
      "val Loss: 0.1871 Acc: 0.9378\n",
      "Epoch 11/23\n",
      "----------\n",
      "Length of train dataset: 1887\n",
      "train Loss: 0.2664 Acc: 0.9041\n",
      "Length of val dataset: 209\n",
      "val Loss: 0.1865 Acc: 0.9378\n",
      "Epoch 12/23\n",
      "----------\n",
      "Length of train dataset: 1887\n",
      "train Loss: 0.2639 Acc: 0.9051\n",
      "Length of val dataset: 209\n",
      "val Loss: 0.1866 Acc: 0.9378\n",
      "Epoch 13/23\n",
      "----------\n",
      "Length of train dataset: 1887\n",
      "train Loss: 0.2634 Acc: 0.9025\n",
      "Length of val dataset: 209\n",
      "val Loss: 0.1847 Acc: 0.9378\n",
      "Epoch 14/23\n",
      "----------\n",
      "Length of train dataset: 1887\n",
      "train Loss: 0.2546 Acc: 0.9083\n",
      "Length of val dataset: 209\n",
      "val Loss: 0.1848 Acc: 0.9378\n",
      "Epoch 15/23\n",
      "----------\n",
      "Length of train dataset: 1887\n",
      "train Loss: 0.2728 Acc: 0.9014\n",
      "Length of val dataset: 209\n",
      "val Loss: 0.1821 Acc: 0.9378\n",
      "Epoch 16/23\n",
      "----------\n",
      "Length of train dataset: 1887\n",
      "train Loss: 0.2611 Acc: 0.9067\n",
      "Length of val dataset: 209\n",
      "val Loss: 0.1813 Acc: 0.9378\n",
      "Epoch 17/23\n",
      "----------\n",
      "Length of train dataset: 1887\n",
      "train Loss: 0.2614 Acc: 0.9057\n",
      "Length of val dataset: 209\n",
      "val Loss: 0.1802 Acc: 0.9378\n",
      "Epoch 18/23\n",
      "----------\n",
      "Length of train dataset: 1887\n",
      "train Loss: 0.2477 Acc: 0.9136\n",
      "Length of val dataset: 209\n",
      "val Loss: 0.1794 Acc: 0.9378\n",
      "Epoch 19/23\n",
      "----------\n",
      "Length of train dataset: 1887\n",
      "train Loss: 0.2623 Acc: 0.9073\n",
      "Length of val dataset: 209\n",
      "val Loss: 0.1781 Acc: 0.9378\n",
      "Epoch 20/23\n",
      "----------\n",
      "Length of train dataset: 1887\n",
      "train Loss: 0.2608 Acc: 0.9041\n",
      "Length of val dataset: 209\n",
      "val Loss: 0.1776 Acc: 0.9378\n",
      "Epoch 21/23\n",
      "----------\n",
      "Length of train dataset: 1887\n",
      "train Loss: 0.2415 Acc: 0.9157\n",
      "Length of val dataset: 209\n",
      "val Loss: 0.1754 Acc: 0.9378\n",
      "Epoch 22/23\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train dataset: 1887\n",
      "train Loss: 0.2461 Acc: 0.9163\n",
      "Length of val dataset: 209\n",
      "val Loss: 0.1757 Acc: 0.9378\n",
      "Epoch 23/23\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs, history=None, checkpoint_save_path = None,\n",
    "                scheduler=None, is_inception=False):\n",
    "    since = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    \n",
    "    try:\n",
    "        history_accuracy = {\"train\":history[\"accuracy\"][\"train\"], \"val\":history[\"accuracy\"][\"val\"]}\n",
    "        history_loss = {\"train\":history[\"loss\"][\"train\"], \"val\":history[\"loss\"][\"val\"]}\n",
    "    except:\n",
    "        history_accuracy = {\"train\":[], \"val\":[]}\n",
    "        history_loss = {\"train\":[], \"val\":[]}\n",
    "    \n",
    "    best_loss = 1.0\n",
    "    best_acc = 0.0\n",
    "    # Is this continuing from former training?\n",
    "    pretrained_epochs = len(history_accuracy[\"train\"])\n",
    "    \n",
    "    for epoch in range(pretrained_epochs+1, pretrained_epochs+num_epochs+1):\n",
    "        print('Epoch {}/{}'.format(epoch, pretrained_epochs+num_epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in dataloaders.keys():\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for data in dataloaders[phase]:\n",
    "                inputs=data[\"image\"]\n",
    "                labels=data[\"label\"]\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    # Special case for inception because in training it has an auxiliary output. In train\n",
    "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "                    #   but in testing we only consider the final output.\n",
    "                    if is_inception and phase == 'train':\n",
    "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
    "                        outputs, aux_outputs = model(inputs)\n",
    "                        loss1 = criterion(outputs, labels)\n",
    "                        loss2 = criterion(aux_outputs, labels)\n",
    "                        loss = loss1 + 0.4*loss2\n",
    "                    else:\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                labels = labels.detach().cpu()\n",
    "                preds = preds.detach().cpu()\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                # for each element in preds, check is equal to each element in labels.data\n",
    "                running_corrects += torch.sum(torch.eq(preds, labels))\n",
    "                #print(running_corrects)\n",
    "                \n",
    "            epoch_loss = running_loss / len(dataloaders[phase].sampler)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].sampler)\n",
    "            print(\"Length of {} dataset: {}\".format(phase, len(dataloaders[phase].sampler)))\n",
    "            \n",
    "            # Record histories\n",
    "            history_accuracy[phase].append(epoch_acc)\n",
    "            history_loss[phase].append(epoch_loss)\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            save_outputs = {\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': best_model_wts,\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'N_CLASSES': N_CLASSES,\n",
    "                    'BATCH_SIZE': BATCH_SIZE,\n",
    "                    'ini_lr': ini_lr,\n",
    "                    'max_layers_to_freeze':max_layers_to_freeze,\n",
    "                    'class_weights':class_weights,\n",
    "                    'random_seed': seed\n",
    "            }\n",
    "            if phase == 'val' and epoch_acc > limit_save_epoch_acc and checkpoint_save_path is not None:\n",
    "                best_loss = epoch_loss\n",
    "                best_acc = epoch_acc\n",
    "                print(\"Achieved current lowest loss of: {} ; accuracy = {}\".format(best_loss, epoch_acc))\n",
    "                saved_checkpoint = os.path.join(checkpoint_save_path,\n",
    "                             'balance[epoch_{}_loss_{:.3f}_acc_{:.3f}].pt'.format((epoch), history_loss[phase][-1],\n",
    "                                                                                        history_accuracy[phase][-1]))\n",
    "                torch.save(save_outputs, saved_checkpoint)\n",
    "                print(\"Saved checkpoint: {}\".format(saved_checkpoint))\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    history = {\"accuracy\":history_accuracy, \"loss\":history_loss}\n",
    "    return model, history, save_outputs\n",
    "\n",
    "\n",
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    # If feature extracting only.\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(18.5, 10.5)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "import datasets\n",
    "import models\n",
    "splits=StratifiedKFold(n_splits=split_k_folds,shuffle=True,random_state=42)\n",
    "foldperf={}\n",
    "def pneumoniaPath(TRAINVAL_DATA_DIR,  flag_includePneumoniaPics):\n",
    "    if flag_includePneumoniaPics:\n",
    "        return os.path.join(TRAINVAL_DATA_DIR,\"PNEUMONIA\")\n",
    "    else:\n",
    "        return None\n",
    "trainVal_dataset = datasets.Coviddataset(normal_path=os.path.join(TRAINVAL_DATA_DIR,\"NORMAL\"),\n",
    "                                      pneumonia_path= pneumoniaPath(TRAINVAL_DATA_DIR, flag_includePneumoniaPics),\n",
    "                                      covid_path=os.path.join(TRAINVAL_DATA_DIR,\"COVID\"),\n",
    "                                      transform = None,\n",
    "                                     NClasses=N_CLASSES, unbias=unbias,channels=num_channels, display_console=True)\n",
    "for fold, (train_idx,val_idx) in enumerate(splits.split(X=np.arange(len(trainVal_dataset)), y=trainVal_dataset.labels)):\n",
    "    print('Fold {}'.format(fold + 1))\n",
    "    \n",
    "    # Subset sample from dataset\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    test_sampler = SubsetRandomSampler(val_idx)\n",
    "    dl_training = DataLoader(datasets.Coviddataset(normal_path=os.path.join(TRAINVAL_DATA_DIR,\"NORMAL\"),\n",
    "                                      pneumonia_path=pneumoniaPath(TRAINVAL_DATA_DIR, flag_includePneumoniaPics),\n",
    "                                      covid_path=os.path.join(TRAINVAL_DATA_DIR,\"COVID\"),\n",
    "                                      transform = train_transforms,\n",
    "                                     NClasses=N_CLASSES, unbias=unbias,channels=num_channels, display_console=False),\n",
    "                             batch_size=BATCH_SIZE, sampler=train_sampler, num_workers=0)\n",
    "    dl_validation = DataLoader(datasets.Coviddataset(normal_path=os.path.join(TRAINVAL_DATA_DIR,\"NORMAL\"),\n",
    "                                      pneumonia_path=pneumoniaPath(TRAINVAL_DATA_DIR, flag_includePneumoniaPics),\n",
    "                                      covid_path=os.path.join(TRAINVAL_DATA_DIR,\"COVID\"),\n",
    "                                      transform = val_transforms,\n",
    "                                     NClasses=N_CLASSES, unbias=unbias,channels=num_channels, display_console=False),\n",
    "                             batch_size=BATCH_SIZE, sampler=test_sampler, num_workers=0)\n",
    "    \n",
    "    dataloaders = {'train':dl_training,'val':dl_validation}\n",
    "    \n",
    "    # DEBUGGING\n",
    "    for phase in dataloaders.keys():\n",
    "        sample = next(iter(dataloaders[phase]))\n",
    "        print(sample.keys())\n",
    "        out = torchvision.utils.make_grid(sample[\"image\"])\n",
    "        #imshow(out)\n",
    "    \n",
    "    # First training using Adam\n",
    "    # Model\n",
    "    model = models.VGG16_Rajaraman(N_CLASSES, max_layer_to_freeze=30, verbose=False) # freeze all layers\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Loss\n",
    "    criterion = torch.nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
    "\n",
    "    # Observe that all parameters are being optimized\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=ini_lr, betas=betas)\n",
    "\n",
    "    # Deterministic\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "    # Train model & save outputs\n",
    "    model, history, save_outputs = train_model(model, dataloaders, criterion, optimizer, num_epochs_classifier,\n",
    "                                 history=None,\n",
    "                                 checkpoint_save_path=None,\n",
    "                                 is_inception=(model_name==\"inception\"))\n",
    "    print(\"+++++++\")\n",
    "    print(\"Fine-Tuning\")\n",
    "    print(\"+++++++\")\n",
    "    # UnFreeze layers\n",
    "    model.freeze_layers_VGG16(layers=np.arange(24,30), freeze=False) # unfreeze convblock 5\n",
    "    total_num = sum(p.numel() for p in model.parameters())\n",
    "    trainable_num = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print('Parameters total: ',total_num)\n",
    "    print('Parameters trainable: ',trainable_num)\n",
    "    # Train using slower method\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.5e-5, weight_decay=0.1)\n",
    "    model, history, save_outputs = train_model(model, dataloaders, criterion, optimizer, num_epochs_finetune,\n",
    "                                 history=history,\n",
    "                                 checkpoint_save_path=None,\n",
    "                                 is_inception=(model_name==\"inception\"))\n",
    "    foldperf['fold{}'.format(fold+1)] = history\n",
    "    \n",
    "    # Saving Output\n",
    "    checkpoint_save_path=os.path.join('checkpoints', str(N_CLASSES)+\"Class\", save_folder_name)\n",
    "    a = Path(checkpoint_save_path)\n",
    "    a.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    save_filename = \"Fold{}[classifier{}_finetune{}].pt\".format(fold+1, num_epochs_classifier, num_epochs_finetune)\n",
    "    saved_checkpoint = os.path.join(checkpoint_save_path, save_filename)\n",
    "    torch.save(save_outputs, saved_checkpoint)\n",
    "    print(\"Saved checkpoint: {}\".format(saved_checkpoint))\n",
    "    \n",
    "    if flag_onlyFirstFold:\n",
    "        print(\"Breaking loop.\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbdccbc-08ff-462f-94a9-ad2c9e834fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training complete\")\n",
    "# Find the best fold\n",
    "flag_debug=False\n",
    "output_save_directory=checkpoint_save_path\n",
    "\n",
    "# AVERAGE PERFORMANCE\n",
    "testl_f,tl_f,testa_f,ta_f=[],[],[],[]\n",
    "k=len(foldperf.keys())#split_k_folds\n",
    "for f in range(1,k+1):\n",
    "    tl_f.append(np.mean(foldperf['fold{}'.format(f)]['loss']['train']))\n",
    "    testl_f.append(np.mean(foldperf['fold{}'.format(f)]['loss']['val']))\n",
    "\n",
    "    ta_f.append(np.mean(foldperf['fold{}'.format(f)]['accuracy']['train']))\n",
    "    testa_f.append(np.mean(foldperf['fold{}'.format(f)]['accuracy']['val']))\n",
    "\n",
    "print('Performance of {} fold cross validation'.format(k))\n",
    "print(\"Average Training Loss: {:.3f} \\t Average Test Loss: {:.3f} \\t Average Training Acc: {:.3f} \\t Average Test Acc: {:.3f}\"\n",
    "      .format(np.mean(tl_f),np.mean(testl_f),np.mean(ta_f),np.mean(testa_f)))\n",
    "print(\"Best fold: {}\".format(np.argmax(testa_f)+1))\n",
    "\n",
    "import json\n",
    "save_dict = {\"Loss\":{\"Training\":np.mean(tl_f),\"Validation\":np.mean(testl_f)}, \n",
    "             \"Accuracy\":{\"Training\":np.mean(ta_f), \"Validation\":np.mean(testa_f)}}\n",
    "with open(os.path.join(output_save_directory,'data.json'), 'w') as fp:\n",
    "    json.dump(save_dict, fp)\n",
    "\n",
    "# Averaging accuracy and loss\n",
    "diz_ep = {'train_loss_ep':[],'test_loss_ep':[],'train_acc_ep':[],'test_acc_ep':[]}\n",
    "for i in range(0,num_epochs_classifier+num_epochs_finetune):\n",
    "    diz_ep['train_loss_ep'].append(np.mean([foldperf['fold{}'.format(f+1)]['loss']['train'][i] for f in range(k)]))\n",
    "    diz_ep['test_loss_ep'].append(np.mean([foldperf['fold{}'.format(f+1)]['loss']['val'][i] for f in range(k)]))\n",
    "    diz_ep['train_acc_ep'].append(np.mean([foldperf['fold{}'.format(f+1)]['accuracy']['train'][i] for f in range(k)]))\n",
    "    diz_ep['test_acc_ep'].append(np.mean([foldperf['fold{}'.format(f+1)]['accuracy']['val'][i] for f in range(k)]))\n",
    "\n",
    "# Plot losses\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.semilogy(diz_ep['train_loss_ep'], label='Train')\n",
    "plt.semilogy(diz_ep['test_loss_ep'], label='Validation')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "#plt.grid()\n",
    "plt.legend()\n",
    "if not flag_debug:\n",
    "    plt.savefig(os.path.join(output_save_directory, \"average_fold_loss\"+\".png\"))\n",
    "plt.show()\n",
    "\n",
    "# Plot accuracies\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.semilogy(diz_ep['train_acc_ep'], label='Train')\n",
    "plt.semilogy(diz_ep['test_acc_ep'], label='Validation')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "#plt.grid()\n",
    "plt.legend()\n",
    "if not flag_debug:\n",
    "    plt.savefig(os.path.join(output_save_directory, \"average_fold_accuracy\"+\".png\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34393c15-00d5-46fd-8789-f4cdf0e400fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(foldperf['fold1']['loss']['val']))\n",
    "\n",
    "print(\"Length of validation idx: {}\".format(len(val_idx)))\n",
    "len(dl_validation.sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a52cb27-1daa-4fd8-b2dd-eb0a2d05bbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epoch_list= list(i for i in range(1,num_epochs+1))\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(15,8))\n",
    "ax[0].set(title='Train/Val Loss', xlabel='Epoch', ylabel='Loss' )\n",
    "ax[0].plot(epoch_list, history[\"loss\"]['train'],linewidth=2,linestyle=':',label='Train Loss', marker='o')\n",
    "ax[0].plot(epoch_list, history[\"loss\"]['val'], linewidth=1, linestyle='--', label='Val Loss', marker='+')\n",
    "ax[0].legend(loc=2)\n",
    "\n",
    "ax[1].set(title='Train/Val Acc', xlabel='Epoch', ylabel='Acc' )\n",
    "ax[1].plot(epoch_list, history[\"accuracy\"]['train'], linewidth=2, linestyle=':', label='Train Acc', marker='o')\n",
    "ax[1].plot(epoch_list, history[\"accuracy\"]['val'], linewidth=1, linestyle='--', label='Val Acc', marker='+')\n",
    "ax[1].legend(loc=2)\n",
    "plt.savefig(os.path.join(checkpoint_save_path,\"lossaccpic_\"+str(N_CLASSES)+\"class.png\"), bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
