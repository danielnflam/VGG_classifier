{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7939c6bd-0a8d-4375-95db-3981e73d19fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "G:/DanielLam/Hongfei_VGG_classifier_training_data/Rajaraman/augmented/\n",
      "G217p400e_R217p200e_8kfold_Daniel\\VGG16_augmented_Rajaraman_trainingData\n",
      "Total Num Folds: 8\n",
      "Total Num Epochs: 45\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.datasets\n",
    "import torchvision.models\n",
    "import torchvision.transforms\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, SubsetRandomSampler, ConcatDataset\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from PIL import Image, ImageOps\n",
    "import os, sys, math, random, copy, time\n",
    "import datasets, custom_transforms, models\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "seed = 0\n",
    "#split_k_folds=10\n",
    "split_k_folds=8\n",
    "flag_selectFold, selectedFold = False, None\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# Parameters to Change\n",
    "N_CLASSES = 2\n",
    "BATCH_SIZE = 8\n",
    "#num_epochs_classifier=5\n",
    "num_epochs_classifier=5\n",
    "num_epochs_finetune=40\n",
    "finetune_lr = 5e-6\n",
    "#finetune_weightdecay = 0.18\n",
    "finetune_weightdecay = 0.01\n",
    "\n",
    "# top_cutoff_percent = 0.15 # 0.08 COVID-Net paper by Wang et al.\n",
    "flag_includePneumoniaPics = False\n",
    "\n",
    "flag_preaugmented = True\n",
    "\n",
    "TRAINVAL_DATA_DIR = 'G:/DanielLam/Hongfei_VGG_classifier_training_data/Rajaraman/augmented/'\n",
    "#TRAINVAL_DATA_DIR = 'F:/VGG_classifier/SunDataSets_Reduced_256_None_new/SunDataSets_Reduced_256_None_new/trainVal/'\n",
    "\n",
    "#save_folder_name =  os.path.join(\"G217R217_EpochG_400_EpochR_200_Gusarev_epoch40\", \"VGG16_Rajaraman_None_NORMAL_COVID_2_class\")\n",
    "save_folder_name =  os.path.join(\"G217p400e_R217p200e_8kfold_Daniel\", \n",
    "                                 \"VGG16_augmented_Rajaraman_trainingData\")\n",
    "print(TRAINVAL_DATA_DIR)\n",
    "print(save_folder_name)\n",
    "print(\"Total Num Folds: {}\".format(split_k_folds))\n",
    "print(\"Total Num Epochs: {}\".format(num_epochs_classifier + num_epochs_finetune))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0779c6-83f1-420a-aec5-6ce4d4050920",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c72d626-cde7-45e2-87fe-11391a51394f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOCKED\n",
    "# Preprocessing settings:\n",
    "interp_mode = torchvision.transforms.InterpolationMode.NEAREST\n",
    "image_size_to_VGG =224 # resize input images to this size in VGG\n",
    "model_name = \"VGG\"\n",
    "num_channels = 3 # because VGG is trained on RGB images\n",
    "unbias=False\n",
    "limit_save_epoch_acc=0.80\n",
    "\n",
    "\n",
    "# Learning Rates\n",
    "betas = (0.9,0.999)\n",
    "ini_lr= 1e-3\n",
    "max_layers_to_freeze = 28 # 30 means that only the last linear classifier is left to train\n",
    "class_weights = torch.Tensor([1, 3075/3584]) # NONCOVID, COVID\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f1cfb2-cc4d-4dc2-b485-2e617e9934ee",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "907a6aea-da68-46b1-9b6a-85eef2747b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing and Transforms\n",
    "# Assumes importing images as PIL Images\n",
    "normalize = torchvision.transforms.Normalize(\n",
    "                                [0.485, 0.456, 0.406],\n",
    "                                [0.229, 0.224, 0.225])\n",
    "\n",
    "class Equalise(object):\n",
    "    # Histogram equalisation\n",
    "    # Only works on PIL images\n",
    "    def __init__(self, mask=None):\n",
    "        self.mask = mask\n",
    "    def __call__(self, image):\n",
    "        return ImageOps.equalize(image, self.mask)\n",
    "    \n",
    "class ImageComplement(object):  #What is its function? for normalize???\n",
    "    # Flip image intensities (i.e. black becomes white, white becomes black)\n",
    "    # Assumes input image is a tensor with range[0,1]\n",
    "    def __init__(self, probability=0.5):\n",
    "        self.probability = probability\n",
    "    def __call__(self, image):\n",
    "        activate = np.random.uniform(0,1)\n",
    "        if activate < self.probability:\n",
    "            # Flip\n",
    "            max_image = torch.max(image)\n",
    "            min_image = torch.min(image)\n",
    "#            print(\"min:{},max:{}\".format(min_image, max_image))\n",
    "            image = (image-min_image)/(max_image-min_image) # range [0,1]\n",
    "            image = (1-image)*(max_image-min_image) + min_image # back to original range\n",
    "        return image\n",
    "\n",
    "\n",
    "\n",
    "train_transforms=torchvision.transforms.Compose([\n",
    "                                    torchvision.transforms.ToTensor(),  \n",
    "                                    ImageComplement(),\n",
    "#                                    custom_transforms.COVIDNetProcessing(top_cutoff_percent),  # for cut-off label????\n",
    "                                    torchvision.transforms.Resize(image_size_to_VGG, interpolation=interp_mode), # PIL image\n",
    "                                    torchvision.transforms.CenterCrop(image_size_to_VGG),\n",
    "                                    torchvision.transforms.RandomHorizontalFlip(), \n",
    "                                    torchvision.transforms.ColorJitter(brightness=0.1), # this jitters brightness It makes sense??\n",
    "                                    torchvision.transforms.RandomAffine(degrees=10,translate=(0.1,0.1),scale=(0.9,1.1)),\n",
    "                                    normalize,\n",
    "                                    ])\n",
    "\n",
    "val_transforms=torchvision.transforms.Compose([\n",
    "                                    torchvision.transforms.ToTensor(),\n",
    "#                                    custom_transforms.COVIDNetProcessing(top_cutoff_percent),\n",
    "                                    torchvision.transforms.Resize(image_size_to_VGG, interpolation=interp_mode),\n",
    "                                    torchvision.transforms.CenterCrop(image_size_to_VGG),\n",
    "                                    normalize,\n",
    "                                ])\n",
    "if flag_preaugmented:\n",
    "    train_transforms = val_transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e10bdf-793e-4cf0-a5f3-af0aac5a9555",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0964cfc4-530b-46b3-bc01-35fa4cba5014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None Path\n",
      "RAW DATASET STATISTICS:-----------\n",
      "Normal:3075, Pneumonia:0, COVID:3584\n",
      "2-Class Dataset Statistics:-----------\n",
      "Noncovid:3075, COVID:3584\n",
      "===========\n",
      "Fold 1\n",
      "===========\n",
      "===========\n",
      "dict_keys(['name', 'image', 'label'])\n",
      "dict_keys(['name', 'image', 'label'])\n",
      "Parameters total:  14715714\n",
      "Parameters trainable:  1026\n",
      "pretrained_epochs:  0\n",
      "Epoch 1/5\n",
      "----------\n",
      "Length of train dataset: 5826\n",
      "train Loss: 0.3300 Acc: 0.8864\n",
      "Length of val dataset: 833\n",
      "val Loss: 0.1732 Acc: 0.9616\n",
      "Epoch 2/5\n",
      "----------\n",
      "Length of train dataset: 5826\n",
      "train Loss: 0.2161 Acc: 0.9195\n",
      "Length of val dataset: 833\n",
      "val Loss: 0.1229 Acc: 0.9772\n",
      "Epoch 3/5\n",
      "----------\n",
      "Length of train dataset: 5826\n",
      "train Loss: 0.1938 Acc: 0.9271\n",
      "Length of val dataset: 833\n",
      "val Loss: 0.1088 Acc: 0.9736\n",
      "Epoch 4/5\n",
      "----------\n",
      "Length of train dataset: 5826\n",
      "train Loss: 0.1784 Acc: 0.9332\n",
      "Length of val dataset: 833\n",
      "val Loss: 0.0932 Acc: 0.9772\n",
      "Epoch 5/5\n",
      "----------\n",
      "Length of train dataset: 5826\n",
      "train Loss: 0.1734 Acc: 0.9341\n",
      "Length of val dataset: 833\n",
      "val Loss: 0.0873 Acc: 0.9784\n",
      "Training complete in 6m 35s\n",
      "Best val Acc: 0.000000\n",
      "++++++++++\n",
      "Parameters total:  14715714\n",
      "Parameters trainable:  7080450\n",
      "pretrained_epochs:  5\n",
      "Epoch 6/45\n",
      "----------\n",
      "Length of train dataset: 5826\n",
      "train Loss: 0.1692 Acc: 0.9355\n",
      "Length of val dataset: 833\n",
      "val Loss: 0.0858 Acc: 0.9784\n",
      "Epoch 7/45\n",
      "----------\n",
      "Length of train dataset: 5826\n",
      "train Loss: 0.1704 Acc: 0.9365\n",
      "Length of val dataset: 833\n",
      "val Loss: 0.0848 Acc: 0.9784\n",
      "Epoch 8/45\n",
      "----------\n",
      "Length of train dataset: 5826\n",
      "train Loss: 0.1650 Acc: 0.9394\n",
      "Length of val dataset: 833\n",
      "val Loss: 0.0846 Acc: 0.9784\n",
      "Epoch 9/45\n",
      "----------\n",
      "Length of train dataset: 5826\n",
      "train Loss: 0.1649 Acc: 0.9386\n",
      "Length of val dataset: 833\n",
      "val Loss: 0.0835 Acc: 0.9772\n",
      "Epoch 10/45\n",
      "----------\n",
      "Length of train dataset: 5826\n",
      "train Loss: 0.1580 Acc: 0.9428\n",
      "Length of val dataset: 833\n",
      "val Loss: 0.0828 Acc: 0.9772\n",
      "Epoch 11/45\n",
      "----------\n",
      "Length of train dataset: 5826\n",
      "train Loss: 0.1596 Acc: 0.9420\n",
      "Length of val dataset: 833\n",
      "val Loss: 0.0824 Acc: 0.9772\n",
      "Epoch 12/45\n",
      "----------\n",
      "Length of train dataset: 5826\n",
      "train Loss: 0.1600 Acc: 0.9387\n",
      "Length of val dataset: 833\n",
      "val Loss: 0.0812 Acc: 0.9772\n",
      "Epoch 13/45\n",
      "----------\n",
      "Length of train dataset: 5826\n",
      "train Loss: 0.1612 Acc: 0.9351\n",
      "Length of val dataset: 833\n",
      "val Loss: 0.0811 Acc: 0.9772\n",
      "Epoch 14/45\n",
      "----------\n",
      "Length of train dataset: 5826\n",
      "train Loss: 0.1589 Acc: 0.9367\n",
      "Length of val dataset: 833\n",
      "val Loss: 0.0796 Acc: 0.9772\n",
      "Epoch 15/45\n",
      "----------\n",
      "Length of train dataset: 5826\n",
      "train Loss: 0.1573 Acc: 0.9404\n",
      "Length of val dataset: 833\n",
      "val Loss: 0.0789 Acc: 0.9772\n",
      "Epoch 16/45\n",
      "----------\n",
      "Length of train dataset: 5826\n",
      "train Loss: 0.1647 Acc: 0.9331\n",
      "Length of val dataset: 833\n",
      "val Loss: 0.0779 Acc: 0.9772\n",
      "Epoch 17/45\n",
      "----------\n",
      "Length of train dataset: 5826\n",
      "train Loss: 0.1564 Acc: 0.9404\n",
      "Length of val dataset: 833\n",
      "val Loss: 0.0769 Acc: 0.9772\n",
      "Epoch 18/45\n",
      "----------\n",
      "Length of train dataset: 5826\n",
      "train Loss: 0.1528 Acc: 0.9440\n",
      "Length of val dataset: 833\n",
      "val Loss: 0.0770 Acc: 0.9772\n",
      "Epoch 19/45\n",
      "----------\n",
      "Length of train dataset: 5826\n",
      "train Loss: 0.1549 Acc: 0.9389\n",
      "Length of val dataset: 833\n",
      "val Loss: 0.0767 Acc: 0.9772\n",
      "Epoch 20/45\n",
      "----------\n",
      "Length of train dataset: 5826\n",
      "train Loss: 0.1479 Acc: 0.9440\n",
      "Length of val dataset: 833\n",
      "val Loss: 0.0753 Acc: 0.9772\n",
      "Epoch 21/45\n",
      "----------\n",
      "Length of train dataset: 5826\n",
      "train Loss: 0.1454 Acc: 0.9413\n",
      "Length of val dataset: 833\n",
      "val Loss: 0.0753 Acc: 0.9772\n",
      "Epoch 22/45\n",
      "----------\n",
      "Length of train dataset: 5826\n",
      "train Loss: 0.1471 Acc: 0.9440\n",
      "Length of val dataset: 833\n",
      "val Loss: 0.0738 Acc: 0.9772\n",
      "Epoch 23/45\n",
      "----------\n",
      "Length of train dataset: 5826\n",
      "train Loss: 0.1526 Acc: 0.9439\n",
      "Length of val dataset: 833\n",
      "val Loss: 0.0736 Acc: 0.9772\n",
      "Epoch 24/45\n",
      "----------\n",
      "Length of train dataset: 5826\n",
      "train Loss: 0.1477 Acc: 0.9423\n",
      "Length of val dataset: 833\n",
      "val Loss: 0.0727 Acc: 0.9784\n",
      "Epoch 25/45\n",
      "----------\n",
      "Length of train dataset: 5826\n",
      "train Loss: 0.1456 Acc: 0.9451\n",
      "Length of val dataset: 833\n",
      "val Loss: 0.0726 Acc: 0.9784\n",
      "Epoch 26/45\n",
      "----------\n",
      "Length of train dataset: 5826\n",
      "train Loss: 0.1470 Acc: 0.9435\n",
      "Length of val dataset: 833\n",
      "val Loss: 0.0720 Acc: 0.9784\n",
      "Epoch 27/45\n",
      "----------\n",
      "Length of train dataset: 5826\n",
      "train Loss: 0.1444 Acc: 0.9478\n",
      "Length of val dataset: 833\n",
      "val Loss: 0.0714 Acc: 0.9784\n",
      "Epoch 28/45\n",
      "----------\n",
      "Length of train dataset: 5826\n",
      "train Loss: 0.1422 Acc: 0.9490\n",
      "Length of val dataset: 833\n",
      "val Loss: 0.0705 Acc: 0.9808\n",
      "Epoch 29/45\n",
      "----------\n",
      "Length of train dataset: 5826\n",
      "train Loss: 0.1439 Acc: 0.9466\n",
      "Length of val dataset: 833\n",
      "val Loss: 0.0702 Acc: 0.9808\n",
      "Epoch 30/45\n",
      "----------\n",
      "Length of train dataset: 5826\n",
      "train Loss: 0.1390 Acc: 0.9483\n",
      "Length of val dataset: 833\n",
      "val Loss: 0.0696 Acc: 0.9808\n",
      "Epoch 31/45\n",
      "----------\n",
      "Length of train dataset: 5826\n",
      "train Loss: 0.1432 Acc: 0.9461\n",
      "Length of val dataset: 833\n",
      "val Loss: 0.0692 Acc: 0.9808\n",
      "Epoch 32/45\n",
      "----------\n",
      "Length of train dataset: 5826\n",
      "train Loss: 0.1412 Acc: 0.9490\n",
      "Length of val dataset: 833\n",
      "val Loss: 0.0686 Acc: 0.9808\n",
      "Epoch 33/45\n",
      "----------\n",
      "Length of train dataset: 5826\n",
      "train Loss: 0.1369 Acc: 0.9506\n",
      "Length of val dataset: 833\n",
      "val Loss: 0.0683 Acc: 0.9808\n",
      "Epoch 34/45\n",
      "----------\n",
      "Length of train dataset: 5826\n",
      "train Loss: 0.1396 Acc: 0.9485\n",
      "Length of val dataset: 833\n",
      "val Loss: 0.0675 Acc: 0.9808\n",
      "Epoch 35/45\n",
      "----------\n",
      "Length of train dataset: 5826\n",
      "train Loss: 0.1316 Acc: 0.9511\n",
      "Length of val dataset: 833\n",
      "val Loss: 0.0669 Acc: 0.9808\n",
      "Epoch 36/45\n",
      "----------\n",
      "Length of train dataset: 5826\n",
      "train Loss: 0.1353 Acc: 0.9511\n",
      "Length of val dataset: 833\n",
      "val Loss: 0.0667 Acc: 0.9808\n",
      "Epoch 37/45\n",
      "----------\n",
      "Length of train dataset: 5826\n",
      "train Loss: 0.1356 Acc: 0.9499\n",
      "Length of val dataset: 833\n",
      "val Loss: 0.0661 Acc: 0.9820\n",
      "Epoch 38/45\n",
      "----------\n",
      "Length of train dataset: 5826\n",
      "train Loss: 0.1315 Acc: 0.9499\n",
      "Length of val dataset: 833\n",
      "val Loss: 0.0659 Acc: 0.9820\n",
      "Epoch 39/45\n",
      "----------\n",
      "Length of train dataset: 5826\n",
      "train Loss: 0.1409 Acc: 0.9454\n",
      "Length of val dataset: 833\n",
      "val Loss: 0.0651 Acc: 0.9820\n",
      "Epoch 40/45\n",
      "----------\n",
      "Length of train dataset: 5826\n",
      "train Loss: 0.1265 Acc: 0.9535\n",
      "Length of val dataset: 833\n",
      "val Loss: 0.0650 Acc: 0.9820\n",
      "Epoch 41/45\n",
      "----------\n",
      "Length of train dataset: 5826\n",
      "train Loss: 0.1356 Acc: 0.9502\n",
      "Length of val dataset: 833\n",
      "val Loss: 0.0647 Acc: 0.9820\n",
      "Epoch 42/45\n",
      "----------\n",
      "Length of train dataset: 5826\n",
      "train Loss: 0.1311 Acc: 0.9543\n",
      "Length of val dataset: 833\n",
      "val Loss: 0.0640 Acc: 0.9820\n",
      "Epoch 43/45\n",
      "----------\n",
      "Length of train dataset: 5826\n",
      "train Loss: 0.1284 Acc: 0.9537\n",
      "Length of val dataset: 833\n",
      "val Loss: 0.0639 Acc: 0.9820\n",
      "Epoch 44/45\n",
      "----------\n",
      "Length of train dataset: 5826\n",
      "train Loss: 0.1277 Acc: 0.9531\n",
      "Length of val dataset: 833\n",
      "val Loss: 0.0634 Acc: 0.9832\n",
      "Epoch 45/45\n",
      "----------\n",
      "Length of train dataset: 5826\n",
      "train Loss: 0.1279 Acc: 0.9521\n",
      "Length of val dataset: 833\n",
      "val Loss: 0.0627 Acc: 0.9832\n",
      "Training complete in 38m 44s\n",
      "Best val Acc: 0.000000\n",
      "Saved checkpoint: checkpoints\\2Class\\G217p400e_R217p200e_8kfold_Daniel\\VGG16_augmented_Rajaraman_trainingData\\Fold1[classifier5_finetune40_WD0.01].pt\n",
      "Fold 2\n",
      "===========\n",
      "===========\n",
      "dict_keys(['name', 'image', 'label'])\n",
      "dict_keys(['name', 'image', 'label'])\n",
      "Parameters total:  14715714\n",
      "Parameters trainable:  1026\n",
      "pretrained_epochs:  0\n",
      "Epoch 1/5\n",
      "----------\n",
      "Length of train dataset: 5826\n",
      "train Loss: 0.3306 Acc: 0.8833\n",
      "Length of val dataset: 833\n",
      "val Loss: 0.1745 Acc: 0.9652\n",
      "Epoch 2/5\n",
      "----------\n",
      "Length of train dataset: 5826\n",
      "train Loss: 0.2115 Acc: 0.9269\n",
      "Length of val dataset: 833\n",
      "val Loss: 0.1366 Acc: 0.9640\n",
      "Epoch 3/5\n",
      "----------\n",
      "Length of train dataset: 5826\n",
      "train Loss: 0.1870 Acc: 0.9334\n",
      "Length of val dataset: 833\n",
      "val Loss: 0.1168 Acc: 0.9640\n",
      "Epoch 4/5\n",
      "----------\n",
      "Length of train dataset: 5826\n",
      "train Loss: 0.1802 Acc: 0.9298\n",
      "Length of val dataset: 833\n",
      "val Loss: 0.1064 Acc: 0.9676\n",
      "Epoch 5/5\n",
      "----------\n",
      "Length of train dataset: 5826\n",
      "train Loss: 0.1699 Acc: 0.9353\n",
      "Length of val dataset: 833\n",
      "val Loss: 0.0912 Acc: 0.9736\n",
      "Training complete in 4m 46s\n",
      "Best val Acc: 0.000000\n",
      "++++++++++\n",
      "Parameters total:  14715714\n",
      "Parameters trainable:  7080450\n",
      "pretrained_epochs:  5\n",
      "Epoch 6/45\n",
      "----------\n",
      "Length of train dataset: 5826\n",
      "train Loss: 0.1641 Acc: 0.9375\n",
      "Length of val dataset: 833\n",
      "val Loss: 0.0905 Acc: 0.9748\n",
      "Epoch 7/45\n",
      "----------\n",
      "Length of train dataset: 5826\n",
      "train Loss: 0.1643 Acc: 0.9370\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of val dataset: 833\n",
      "val Loss: 0.0893 Acc: 0.9748\n",
      "Epoch 8/45\n",
      "----------\n",
      "Length of train dataset: 5826\n",
      "train Loss: 0.1635 Acc: 0.9358\n",
      "Length of val dataset: 833\n",
      "val Loss: 0.0884 Acc: 0.9772\n",
      "Epoch 9/45\n",
      "----------\n",
      "Length of train dataset: 5826\n",
      "train Loss: 0.1589 Acc: 0.9413\n",
      "Length of val dataset: 833\n",
      "val Loss: 0.0876 Acc: 0.9772\n",
      "Epoch 10/45\n",
      "----------\n",
      "Length of train dataset: 5826\n",
      "train Loss: 0.1582 Acc: 0.9382\n",
      "Length of val dataset: 833\n",
      "val Loss: 0.0867 Acc: 0.9772\n",
      "Epoch 11/45\n",
      "----------\n",
      "Length of train dataset: 5826\n",
      "train Loss: 0.1536 Acc: 0.9373\n",
      "Length of val dataset: 833\n",
      "val Loss: 0.0858 Acc: 0.9772\n",
      "Epoch 12/45\n",
      "----------\n",
      "Length of train dataset: 5826\n",
      "train Loss: 0.1547 Acc: 0.9411\n",
      "Length of val dataset: 833\n",
      "val Loss: 0.0848 Acc: 0.9772\n",
      "Epoch 13/45\n",
      "----------\n",
      "Length of train dataset: 5826\n",
      "train Loss: 0.1567 Acc: 0.9425\n",
      "Length of val dataset: 833\n",
      "val Loss: 0.0847 Acc: 0.9772\n",
      "Epoch 14/45\n",
      "----------\n",
      "Length of train dataset: 5826\n",
      "train Loss: 0.1505 Acc: 0.9440\n",
      "Length of val dataset: 833\n",
      "val Loss: 0.0832 Acc: 0.9772\n",
      "Epoch 15/45\n",
      "----------\n",
      "Length of train dataset: 5826\n",
      "train Loss: 0.1531 Acc: 0.9416\n",
      "Length of val dataset: 833\n",
      "val Loss: 0.0829 Acc: 0.9772\n",
      "Epoch 16/45\n",
      "----------\n",
      "Length of train dataset: 5826\n",
      "train Loss: 0.1614 Acc: 0.9375\n",
      "Length of val dataset: 833\n",
      "val Loss: 0.0819 Acc: 0.9772\n",
      "Epoch 17/45\n",
      "----------\n",
      "Length of train dataset: 5826\n",
      "train Loss: 0.1479 Acc: 0.9434\n",
      "Length of val dataset: 833\n",
      "val Loss: 0.0812 Acc: 0.9772\n",
      "Epoch 18/45\n",
      "----------\n",
      "Length of train dataset: 5826\n",
      "train Loss: 0.1538 Acc: 0.9403\n",
      "Length of val dataset: 833\n",
      "val Loss: 0.0805 Acc: 0.9772\n",
      "Epoch 19/45\n",
      "----------\n",
      "Length of train dataset: 5826\n",
      "train Loss: 0.1446 Acc: 0.9476\n",
      "Length of val dataset: 833\n",
      "val Loss: 0.0800 Acc: 0.9772\n",
      "Epoch 20/45\n",
      "----------\n",
      "Length of train dataset: 5826\n",
      "train Loss: 0.1404 Acc: 0.9475\n",
      "Length of val dataset: 833\n",
      "val Loss: 0.0792 Acc: 0.9772\n",
      "Epoch 21/45\n",
      "----------\n",
      "Length of train dataset: 5826\n",
      "train Loss: 0.1423 Acc: 0.9444\n",
      "Length of val dataset: 833\n",
      "val Loss: 0.0785 Acc: 0.9772\n",
      "Epoch 22/45\n",
      "----------\n",
      "Length of train dataset: 5826\n",
      "train Loss: 0.1403 Acc: 0.9473\n",
      "Length of val dataset: 833\n",
      "val Loss: 0.0775 Acc: 0.9772\n",
      "Epoch 23/45\n",
      "----------\n",
      "Length of train dataset: 5826\n",
      "train Loss: 0.1405 Acc: 0.9471\n",
      "Length of val dataset: 833\n",
      "val Loss: 0.0771 Acc: 0.9760\n",
      "Epoch 24/45\n",
      "----------\n",
      "Length of train dataset: 5826\n",
      "train Loss: 0.1413 Acc: 0.9480\n",
      "Length of val dataset: 833\n",
      "val Loss: 0.0765 Acc: 0.9772\n",
      "Epoch 25/45\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs, history=None, checkpoint_save_path = None,\n",
    "                scheduler=None, is_inception=False):\n",
    "    since = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    \n",
    "    try:\n",
    "        history_accuracy = {\"train\":history[\"accuracy\"][\"train\"], \"val\":history[\"accuracy\"][\"val\"]}\n",
    "        history_loss = {\"train\":history[\"loss\"][\"train\"], \"val\":history[\"loss\"][\"val\"]}\n",
    "    except:\n",
    "        history_accuracy = {\"train\":[], \"val\":[]}\n",
    "        history_loss = {\"train\":[], \"val\":[]}\n",
    "    \n",
    "    best_loss = 1.0\n",
    "    best_acc = 0.0\n",
    "    # Is this continuing from former training?\n",
    "    pretrained_epochs = len(history_accuracy[\"train\"])\n",
    "    print(\"pretrained_epochs: \", pretrained_epochs)\n",
    "    \n",
    "    for epoch in range(pretrained_epochs+1, pretrained_epochs+num_epochs+1):\n",
    "        print('Epoch {}/{}'.format(epoch, pretrained_epochs+num_epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in dataloaders.keys():\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for data in dataloaders[phase]:\n",
    "                inputs=data[\"image\"]\n",
    "                labels=data[\"label\"]\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    # Special case for inception because in training it has an auxiliary output. In train\n",
    "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "                    #   but in testing we only consider the final output.\n",
    "                    if is_inception and phase == 'train':\n",
    "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
    "                        outputs, aux_outputs = model(inputs)\n",
    "                        loss1 = criterion(outputs, labels)\n",
    "                        loss2 = criterion(aux_outputs, labels)\n",
    "                        loss = loss1 + 0.4*loss2\n",
    "                    else:\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                labels = labels.detach().cpu()\n",
    "                preds = preds.detach().cpu()\n",
    "                running_loss += loss.item() * inputs.size(0)   #size == batchsize\n",
    "               \n",
    "                # for each element in preds, check is equal to each element in labels.data\n",
    "                running_corrects += torch.sum(torch.eq(preds, labels))\n",
    "                #print(running_corrects)\n",
    "                \n",
    "            epoch_loss = running_loss / len(dataloaders[phase].sampler)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].sampler)\n",
    "            print(\"Length of {} dataset: {}\".format(phase, len(dataloaders[phase].sampler)))\n",
    "            \n",
    "            # Record histories\n",
    "            history_accuracy[phase].append(epoch_acc)\n",
    "            history_loss[phase].append(epoch_loss)\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            save_outputs = {\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': best_model_wts,\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'N_CLASSES': N_CLASSES,\n",
    "                    'BATCH_SIZE': BATCH_SIZE,\n",
    "                    'ini_lr': ini_lr,\n",
    "                    'max_layers_to_freeze':max_layers_to_freeze,\n",
    "                    'class_weights':class_weights,\n",
    "                    'random_seed': seed\n",
    "            }\n",
    "            if phase == 'val' and epoch_acc > limit_save_epoch_acc and checkpoint_save_path is not None:\n",
    "                best_loss = epoch_loss\n",
    "                best_acc = epoch_acc\n",
    "                print(\"Achieved current lowest loss of: {} ; accuracy = {}\".format(best_loss, epoch_acc))\n",
    "                saved_checkpoint = os.path.join(checkpoint_save_path,\n",
    "                             'balance[epoch_{}_loss_{:.3f}_acc_{:.3f}].pt'.format((epoch), history_loss[phase][-1],\n",
    "                                                                                        history_accuracy[phase][-1]))\n",
    "                torch.save(save_outputs, saved_checkpoint)\n",
    "                print(\"Saved checkpoint: {}\".format(saved_checkpoint))\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    history = {\"accuracy\":history_accuracy, \"loss\":history_loss}\n",
    "    return model, history, save_outputs\n",
    "\n",
    "\n",
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    # If feature extracting only.\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(18.5, 10.5)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "import datasets\n",
    "import models\n",
    "splits=StratifiedKFold(n_splits=split_k_folds,shuffle=True,random_state=42)\n",
    "foldperf={}\n",
    "def pneumoniaPath(TRAINVAL_DATA_DIR,  flag_includePneumoniaPics):\n",
    "    if flag_includePneumoniaPics:\n",
    "        return os.path.join(TRAINVAL_DATA_DIR,\"PNEUMONIA\")\n",
    "    else:\n",
    "        return None\n",
    "trainVal_dataset = datasets.Coviddataset(normal_path=os.path.join(TRAINVAL_DATA_DIR,\"NORMAL\"),\n",
    "                                      pneumonia_path= pneumoniaPath(TRAINVAL_DATA_DIR, flag_includePneumoniaPics),\n",
    "                                      covid_path=os.path.join(TRAINVAL_DATA_DIR,\"COVID\"),\n",
    "                                      transform = None,\n",
    "                                     NClasses=N_CLASSES, unbias=unbias,channels=num_channels, display_console=True)\n",
    "for fold, (train_idx,val_idx) in enumerate(splits.split(X=np.arange(len(trainVal_dataset)), y=trainVal_dataset.labels)):\n",
    "    print('Fold {}'.format(fold + 1))\n",
    "    \n",
    "    # Select a fold?  ####################################[I change here]\n",
    "    if flag_selectFold:\n",
    "        if selectedFold is not None and selectedFold >= 1 and selectedFold-1 <= split_k_folds:\n",
    "            if fold != selectedFold-1:\n",
    "                print(\"Breaking loop.\")\n",
    "                continue\n",
    "        else:\n",
    "            raise RuntimeError(\"selectedFold should be a number between 1 and split_k_folds\")\n",
    "            \n",
    "    \n",
    "    # Subset sample from dataset\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    test_sampler = SubsetRandomSampler(val_idx)\n",
    "    dl_training = DataLoader(datasets.Coviddataset(normal_path=os.path.join(TRAINVAL_DATA_DIR,\"NORMAL\"),\n",
    "                                      pneumonia_path=pneumoniaPath(TRAINVAL_DATA_DIR, flag_includePneumoniaPics),\n",
    "                                      covid_path=os.path.join(TRAINVAL_DATA_DIR,\"COVID\"),\n",
    "                                      transform = train_transforms,\n",
    "                                     NClasses=N_CLASSES, unbias=unbias,channels=num_channels, display_console=False),\n",
    "                             batch_size=BATCH_SIZE, sampler=train_sampler, num_workers=0)\n",
    "    dl_validation = DataLoader(datasets.Coviddataset(normal_path=os.path.join(TRAINVAL_DATA_DIR,\"NORMAL\"),\n",
    "                                      pneumonia_path=pneumoniaPath(TRAINVAL_DATA_DIR, flag_includePneumoniaPics),\n",
    "                                      covid_path=os.path.join(TRAINVAL_DATA_DIR,\"COVID\"),\n",
    "                                      transform = val_transforms,\n",
    "                                     NClasses=N_CLASSES, unbias=unbias,channels=num_channels, display_console=False),\n",
    "                             batch_size=BATCH_SIZE, sampler=test_sampler, num_workers=0)\n",
    "    \n",
    "    dataloaders = {'train':dl_training,'val':dl_validation}\n",
    "    \n",
    "    # DEBUGGING\n",
    "    for phase in dataloaders.keys():\n",
    "        sample = next(iter(dataloaders[phase]))\n",
    "        print(sample.keys())\n",
    "        out = torchvision.utils.make_grid(sample[\"image\"])\n",
    "        #imshow(out)\n",
    "    \n",
    "    # First training using Adam\n",
    "    # Model\n",
    "    model = models.VGG16_Rajaraman(N_CLASSES, max_layer_to_freeze=30, verbose=False) # freeze all layers\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Loss\n",
    "    criterion = torch.nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
    "\n",
    "    # Observe that all parameters are being optimized\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=ini_lr, betas=betas)\n",
    "\n",
    "    # Deterministic\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "    # Train model & save outputs\n",
    "    model, history, save_outputs = train_model(model, dataloaders, criterion, optimizer, num_epochs_classifier,\n",
    "                                 history=None,\n",
    "                                 checkpoint_save_path=None,\n",
    "                                 is_inception=(model_name==\"inception\"))\n",
    "    print('+' * 10)\n",
    "#    print(\"Fine-Tuning\")\n",
    "#    print(\"+++++++\")\n",
    "    # UnFreeze layers\n",
    "    model.freeze_layers_VGG16(layers=np.arange(24,30), freeze=False) # unfreeze convblock 5\n",
    "    total_num = sum(p.numel() for p in model.parameters())\n",
    "    trainable_num = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print('Parameters total: ',total_num)\n",
    "    print('Parameters trainable: ',trainable_num)\n",
    "    # Train using slower method  [change here]\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=finetune_lr, weight_decay=finetune_weightdecay)\n",
    "#    optimizer = torch.optim.Adam(model.parameters(), lr=finetune_lr, weight_decay=finetune_weightdecay)\n",
    "    model, history, save_outputs = train_model(model, dataloaders, criterion, optimizer, num_epochs_finetune,\n",
    "                                 history=history,\n",
    "                                 checkpoint_save_path=None,\n",
    "                                 is_inception=(model_name==\"inception\"))\n",
    "    foldperf['fold{}'.format(fold+1)] = history\n",
    "    \n",
    "    # Saving Output\n",
    "    checkpoint_save_path=os.path.join('checkpoints', str(N_CLASSES)+\"Class\", save_folder_name)\n",
    "    a = Path(checkpoint_save_path)\n",
    "    a.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    save_filename = \"Fold{}[classifier{}_finetune{}_WD{}].pt\".format(fold+1, num_epochs_classifier, \n",
    "                                                                     num_epochs_finetune, finetune_weightdecay)\n",
    "    saved_checkpoint = os.path.join(checkpoint_save_path, save_filename)\n",
    "    torch.save(save_outputs, saved_checkpoint)\n",
    "    print(\"Saved checkpoint: {}\".format(saved_checkpoint))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbdccbc-08ff-462f-94a9-ad2c9e834fe3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Training complete\")\n",
    "# Find the best fold\n",
    "flag_debug=False\n",
    "output_save_directory=checkpoint_save_path\n",
    "\n",
    "# AVERAGE PERFORMANCE\n",
    "testl_f,tl_f,testa_f,ta_f=[],[],[],[]\n",
    "k=len(foldperf.keys())#split_k_folds\n",
    "if selectedFold is None:\n",
    "    initial_fold = 1\n",
    "else:\n",
    "    initial_fold = selectedFold\n",
    "fold_range = range(initial_fold,initial_fold+k)\n",
    "for f in fold_range:\n",
    "    tl_f.append(np.mean(foldperf['fold{}'.format(f)]['loss']['train']))\n",
    "    testl_f.append(np.mean(foldperf['fold{}'.format(f)]['loss']['val']))\n",
    "\n",
    "    ta_f.append(np.mean(foldperf['fold{}'.format(f)]['accuracy']['train']))\n",
    "    testa_f.append(np.mean(foldperf['fold{}'.format(f)]['accuracy']['val']))\n",
    "\n",
    "print('Performance of {} fold cross validation'.format(k))\n",
    "print(\"Average Training Loss: {:.3f} \\t Average Test Loss: {:.3f} \\t Average Training Acc: {:.3f} \\t Average Test Acc: {:.3f}\"\n",
    "      .format(np.mean(tl_f),np.mean(testl_f),np.mean(ta_f),np.mean(testa_f)))\n",
    "\n",
    "if initial_fold == 1:\n",
    "    print(\"Best fold: {}\".format(np.argmax(testa_f)+1))\n",
    "\n",
    "import json\n",
    "save_dict = {\"Loss\":{\"Training\":np.mean(tl_f),\"Validation\":np.mean(testl_f)}, \n",
    "             \"Accuracy\":{\"Training\":np.mean(ta_f), \"Validation\":np.mean(testa_f)}}\n",
    "with open(os.path.join(output_save_directory,'data.json'), 'w') as fp:\n",
    "    json.dump(save_dict, fp)\n",
    "\n",
    "# Averaging accuracy and loss\n",
    "diz_ep = {'train_loss_ep':[],'test_loss_ep':[],'train_acc_ep':[],'test_acc_ep':[]}\n",
    "for i in range(0, num_epochs_classifier+num_epochs_finetune):\n",
    "    diz_ep['train_loss_ep'].append(np.mean([foldperf['fold{}'.format(f)]['loss']['train'][i] for f in fold_range]))\n",
    "    diz_ep['test_loss_ep'].append(np.mean([foldperf['fold{}'.format(f)]['loss']['val'][i] for f in fold_range]))\n",
    "    diz_ep['train_acc_ep'].append(np.mean([foldperf['fold{}'.format(f)]['accuracy']['train'][i] for f in fold_range]))\n",
    "    diz_ep['test_acc_ep'].append(np.mean([foldperf['fold{}'.format(f)]['accuracy']['val'][i] for f in fold_range]))\n",
    "\n",
    "# Plot losses\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.semilogy(diz_ep['train_loss_ep'], label='Train')\n",
    "plt.semilogy(diz_ep['test_loss_ep'], label='Validation')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "#plt.grid()\n",
    "plt.legend()\n",
    "if not flag_debug:\n",
    "    plt.savefig(os.path.join(output_save_directory, \"average_fold_loss\"+\".png\"))\n",
    "plt.show()\n",
    "\n",
    "# Plot accuracies\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.semilogy(diz_ep['train_acc_ep'], label='Train')\n",
    "plt.semilogy(diz_ep['test_acc_ep'], label='Validation')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "#plt.grid()\n",
    "plt.legend()\n",
    "if not flag_debug:\n",
    "    plt.savefig(os.path.join(output_save_directory, \"average_fold_accuracy\"+\".png\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34393c15-00d5-46fd-8789-f4cdf0e400fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f)\n",
    "print(len(foldperf['fold1']['loss']['val']))\n",
    "\n",
    "print(\"Length of validation idx: {}\".format(len(val_idx)))\n",
    "len(dl_validation.sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a52cb27-1daa-4fd8-b2dd-eb0a2d05bbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#epoch_list= list(i for i in range(1,num_epochs+1))\n",
    "epoch_list = list(i for i in range(1,num_epochs_classifier + num_epochs_finetune+1))\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(15,8))\n",
    "#ax[0].set(title='Train/Val Loss', xlabel='Epoch', ylabel='Loss' )\n",
    "#ax[0].plot(epoch_list, history[\"loss\"]['train'],linewidth=2,linestyle=':',label='Train Loss', marker='o')\n",
    "#ax[0].plot(epoch_list, history[\"loss\"]['val'], linewidth=1, linestyle='--', label='Val Loss', marker='+')\n",
    "#ax[0].legend(loc=2)\n",
    "\n",
    "ax[1].set(title='Train/Val Acc', xlabel='Epoch', ylabel='Acc' )\n",
    "ax[1].plot(epoch_list, history[\"accuracy\"]['train'], linewidth=2, linestyle=':', label='Train Acc', marker='o')\n",
    "ax[1].plot(epoch_list, history[\"accuracy\"]['val'], linewidth=1, linestyle='--', label='Val Acc', marker='+')\n",
    "ax[1].legend(loc=2)\n",
    "plt.savefig(os.path.join(checkpoint_save_path,\"lossaccpic_\"+str(N_CLASSES)+\"class.png\"), bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a57571",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
